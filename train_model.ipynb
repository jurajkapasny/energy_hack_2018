{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd \n",
    "from copy import deepcopy\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, median_absolute_error,mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "# from skopt import BayesSearchCV\n",
    "import datetime\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_path = \"/Users/jurajkapasny/Data/energy_hack/\"\n",
    "# df = pd.read_csv(data_path+\"spotreba_prepared.csv\",sep = \";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/spotreba_prepared.csv\",sep = \";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"timestamp\"] = df[\"Dátum a čas\"] + \" \" + df[\"Unnamed: 1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[\"spotreba\",\"om\",\"timestamp\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spotreba</th>\n",
       "      <th>om</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.211</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-01 00:15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.210</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-01 00:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.210</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-01 00:45:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.206</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-01 01:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.205</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-01 01:15:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   spotreba  om            timestamp\n",
       "0     0.211   1  2016-01-01 00:15:00\n",
       "1     0.210   1  2016-01-01 00:30:00\n",
       "2     0.210   1  2016-01-01 00:45:00\n",
       "3     0.206   1  2016-01-01 01:00:00\n",
       "4     0.205   1  2016-01-01 01:15:00"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    \"\"\"\n",
    "    Frame a time series as a supervised learning dataset.\n",
    "    Arguments:\n",
    "        data: Sequence of observations as a list or NumPy array.\n",
    "        n_in: Number of lag observations as input (X).\n",
    "        n_out: Number of observations as output (y).\n",
    "        dropnan: Boolean whether or not to drop rows with NaN values.\n",
    "    Returns:\n",
    "        Pandas DataFrame of series framed for supervised learning.\n",
    "    \"\"\"\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "#     for i in range(0, n_out):\n",
    "    cols.append(df.shift(-n_out))\n",
    "    if n_out == 1:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "    else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new method saves test_cols and train_cols as a dictionary not tuple\n",
    "def prep_data_to_train_new(input_data, n_in=30, n_out=1,test_size= 0.2,bootstrap=False, bs_replicates = 10, file_name=\"prepared_data\"):\n",
    "    \n",
    "    time_series = {}\n",
    "    ts_test = []\n",
    "    ts_train = []\n",
    "    train_cols = []\n",
    "    test_cols = []\n",
    "    max_index_ts = 0\n",
    "    \n",
    "\n",
    "    columns = [\"timestamp\",\"spotreba\",\"om\"]\n",
    "    cl_group_by = [\"om\",\"timestamp\"]\n",
    "    data_sum = input_data[columns].groupby(cl_group_by).sum().unstack()\n",
    "    data_sum = data_sum[data_sum.notnull().sum(axis=1) > (data_sum.shape[1]*0.8)].transpose().fillna(0)#.index.droplevel()\n",
    "    data_sum.index = data_sum.index.droplevel()\n",
    "#         print(len(data_sum.columns))\n",
    "\n",
    "    columns = data_sum.columns\n",
    "\n",
    "    for i in range(data_sum.shape[1]):\n",
    "        ts = series_to_supervised(data_sum.iloc[:,i].tolist(),n_in=n_in, n_out=n_out).reset_index().drop(\"index\",axis=1)\n",
    "\n",
    "        if bootstrap:\n",
    "            temp_ts = []\n",
    "#                 print(ts.shape)\n",
    "            for random_point in random.sample(range(0,len(ts)), bs_replicates):\n",
    "                temp_ts.append(pd.DataFrame(ts.iloc[random_point,:]).transpose())\n",
    "\n",
    "            time_series[columns[i]] = pd.concat(temp_ts,ignore_index=True)\n",
    "\n",
    "        else:\n",
    "            time_series[columns[i]] = ts\n",
    "\n",
    "\n",
    "\n",
    "    test_set_random_index = random.sample(range(max_index_ts,len(time_series)),\n",
    "                                          int((len(time_series)- max_index_ts)*test_size))\n",
    "\n",
    "    ts_keys = list(time_series.keys())\n",
    "\n",
    "    for index in range(max_index_ts,len(time_series)):\n",
    "        if index in test_set_random_index:\n",
    "            ts_test.append(time_series[ts_keys[index]])\n",
    "            temp_dict_test ={}\n",
    "#             for i in range(len(selected_columns)):\n",
    "            temp_dict_test[\"om\"] = ts_keys[index]\n",
    "\n",
    "            test_cols.append(temp_dict_test)\n",
    "        else:\n",
    "            ts_train.append(time_series[ts_keys[index]])\n",
    "            temp_dict_train ={}\n",
    "#             for i in range(len(selected_columns)):\n",
    "            temp_dict_train[\"om\"] = ts_keys[index]\n",
    "            train_cols.append(temp_dict_train)\n",
    "\n",
    "\n",
    "    max_index_ts = len(time_series)\n",
    "\n",
    "    \n",
    "    ts_train_df = pd.concat(ts_train, ignore_index= True)\n",
    "    ts_test_df = pd.concat(ts_test,ignore_index =True)\n",
    "    \n",
    "    ts_train_df.to_csv(f\"./models/{file_name}_train.csv\",index= False)\n",
    "    ts_test_df.to_csv(f\"./models/{file_name}_test.csv\", index = False)\n",
    "    \n",
    "    pickle.dump(test_cols, open(f\"./models/{file_name}_test_cols.p\",\"wb\"))\n",
    "    pickle.dump(train_cols, open(f\"./models/{file_name}_train_cols.p\",\"wb\"))\n",
    "    \n",
    "    return ts_train_df, ts_test_df, train_cols, test_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10min 2s, sys: 2min 53s, total: 12min 55s\n",
      "Wall time: 12min 17s\n"
     ]
    }
   ],
   "source": [
    "print(\"Preparing data!!!\")\n",
    "# %%time\n",
    "ts_train_df,ts_test_df, train_cols, test_cols = prep_data_to_train_new(input_data = df,\n",
    "                                            n_in=1000,\n",
    "                                            n_out=1,\n",
    "                                            test_size= 0.2,\n",
    "                                            bootstrap=True,\n",
    "                                            bs_replicates = 10000, \n",
    "                                            file_name=\"x1000_bootstrap10000\")\n",
    "print(\"Data prepared!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1(t-1000)</th>\n",
       "      <th>var1(t-999)</th>\n",
       "      <th>var1(t-998)</th>\n",
       "      <th>var1(t-997)</th>\n",
       "      <th>var1(t-996)</th>\n",
       "      <th>var1(t-995)</th>\n",
       "      <th>var1(t-994)</th>\n",
       "      <th>var1(t-993)</th>\n",
       "      <th>var1(t-992)</th>\n",
       "      <th>var1(t-991)</th>\n",
       "      <th>...</th>\n",
       "      <th>var1(t-9)</th>\n",
       "      <th>var1(t-8)</th>\n",
       "      <th>var1(t-7)</th>\n",
       "      <th>var1(t-6)</th>\n",
       "      <th>var1(t-5)</th>\n",
       "      <th>var1(t-4)</th>\n",
       "      <th>var1(t-3)</th>\n",
       "      <th>var1(t-2)</th>\n",
       "      <th>var1(t-1)</th>\n",
       "      <th>var1(t)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.211</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.209</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.211</td>\n",
       "      <td>...</td>\n",
       "      <td>0.262</td>\n",
       "      <td>0.386</td>\n",
       "      <td>0.279</td>\n",
       "      <td>0.362</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.306</td>\n",
       "      <td>0.306</td>\n",
       "      <td>0.305</td>\n",
       "      <td>0.414</td>\n",
       "      <td>0.366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.091</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.193</td>\n",
       "      <td>...</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.522</td>\n",
       "      <td>0.291</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.254</td>\n",
       "      <td>0.288</td>\n",
       "      <td>0.298</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.442</td>\n",
       "      <td>0.382</td>\n",
       "      <td>0.313</td>\n",
       "      <td>...</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0.277</td>\n",
       "      <td>0.288</td>\n",
       "      <td>0.237</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.209</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.213</td>\n",
       "      <td>0.245</td>\n",
       "      <td>0.241</td>\n",
       "      <td>0.452</td>\n",
       "      <td>0.312</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.283</td>\n",
       "      <td>0.291</td>\n",
       "      <td>...</td>\n",
       "      <td>0.239</td>\n",
       "      <td>0.238</td>\n",
       "      <td>0.234</td>\n",
       "      <td>0.237</td>\n",
       "      <td>0.258</td>\n",
       "      <td>0.295</td>\n",
       "      <td>0.296</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.132</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.197</td>\n",
       "      <td>0.192</td>\n",
       "      <td>...</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.209</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.197</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   var1(t-1000)  var1(t-999)  var1(t-998)  var1(t-997)  var1(t-996)  \\\n",
       "0         0.211        0.203        0.211        0.204        0.199   \n",
       "1         0.091        0.091        0.099        0.097        0.181   \n",
       "2         0.522        0.291        0.259        0.254        0.288   \n",
       "3         0.209        0.211        0.213        0.245        0.241   \n",
       "4         0.132        0.099        0.098        0.098        0.101   \n",
       "\n",
       "   var1(t-995)  var1(t-994)  var1(t-993)  var1(t-992)  var1(t-991)   ...     \\\n",
       "0        0.201        0.203        0.209        0.201        0.211   ...      \n",
       "1        0.184        0.185        0.192        0.184        0.193   ...      \n",
       "2        0.298        0.290        0.442        0.382        0.313   ...      \n",
       "3        0.452        0.312        0.270        0.283        0.291   ...      \n",
       "4        0.101        0.164        0.195        0.197        0.192   ...      \n",
       "\n",
       "   var1(t-9)  var1(t-8)  var1(t-7)  var1(t-6)  var1(t-5)  var1(t-4)  \\\n",
       "0      0.262      0.386      0.279      0.362      0.342      0.306   \n",
       "1      0.194      0.201      0.207      0.207      0.192      0.195   \n",
       "2      0.274      0.277      0.288      0.237      0.232      0.122   \n",
       "3      0.239      0.238      0.234      0.237      0.258      0.295   \n",
       "4      0.199      0.206      0.209      0.205      0.197      0.202   \n",
       "\n",
       "   var1(t-3)  var1(t-2)  var1(t-1)  var1(t)  \n",
       "0      0.306      0.305      0.414    0.366  \n",
       "1      0.200      0.194      0.208    0.196  \n",
       "2      0.100      0.102      0.103    0.101  \n",
       "3      0.296      0.274      0.127    0.097  \n",
       "4      0.203      0.202      0.188    0.195  \n",
       "\n",
       "[5 rows x 1001 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(ts_train_df,ts_test_df, cv = 5,type_ = \"RandomForest\",scoring = \"mae\", file_name=\"rf_test\"):\n",
    "    \n",
    "    scores = dict()\n",
    "    \n",
    "    X_train = ts_train_df.iloc[:,:-1]\n",
    "    y_train = ts_train_df.iloc[:,-1:]\n",
    "    \n",
    "    X_test = ts_test_df.iloc[:,:-1]\n",
    "    y_test = ts_test_df.iloc[:,-1:]\n",
    "    \n",
    "        \n",
    "    grid_search = train_model(X_train,y_train, type_ = type_, scoring = scoring, file_name = file_name)\n",
    "    \n",
    "    y_pred = grid_search.best_estimator_.predict(X_test)\n",
    "\n",
    "    r2score = r2_score(y_pred, y_test)\n",
    "    mae = mean_absolute_error(y_pred, y_test)\n",
    "    medae = median_absolute_error(y_pred, y_test)\n",
    "    \n",
    "    \n",
    "    scores[\"cv_score_mean\"] = grid_search.best_score_\n",
    "    scores[\"r2_test_set\"] = r2score\n",
    "    scores[\"mae_test_set\"] = mae\n",
    "    scores[\"medae_test_set\"] = medae\n",
    "    scores[\"X_train_rows\"] = X_train.shape[0]\n",
    "    scores[\"model_max_depth\"] = grid_search.best_params_[\"max_depth\"]\n",
    "    scores[\"model_learning_rate\"] = grid_search.best_params_[\"learning_rate\"]\n",
    "    scores[\"model_n_estimators\"] = grid_search.best_params_[\"n_estimators\"]\n",
    "    scores[\"settings_cv\"] = cv\n",
    "    \n",
    "    scores_df = pd.DataFrame(scores,index=[0])\n",
    "    scores_df.to_csv(f\"./models/{file_name}_model_info.csv\",index= False)\n",
    "#     joblib.dump(regressor, f\"./models/{file_name}.pkl\")\n",
    "        \n",
    "        \n",
    "    return scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X_train,y_train,type_ = \"xgboost\", scoring = \"neg_median_absolute_error\", file_name=\"xgboost_test\", cv=5):\n",
    "    if type_ == \"xgboost\":\n",
    "        \n",
    "        parameters = {\n",
    "                      \"max_depth\" : [6,12, 15],\n",
    "                      \"learning_rate\" : [0.05,0.2],\n",
    "                      \"min_child_weight\":[2,4],\n",
    "                      \"n_estimators\" : [500,1000],\n",
    "                    }\n",
    "\n",
    "        grid_search = GridSearchCV(estimator=XGBRegressor(n_jobs = -1),\n",
    "                                   param_grid=parameters,\n",
    "                                   scoring = scoring,\n",
    "                                   n_jobs=-1,\n",
    "                                   cv = cv,\n",
    "                                   verbose = 10)\n",
    "\n",
    "    elif type_ == \"RandomForest\":\n",
    "        parameters = {\n",
    "                      \"max_depth\" : [5,10],\n",
    "                      \"n_estimators\" : [100,500, 1000],\n",
    "                    }\n",
    "\n",
    "        grid_search = GridSearchCV(estimator=RandomForestRegressor(n_jobs = -1),\n",
    "                                   param_grid=parameters,\n",
    "                                   scoring = scoring,\n",
    "                                   n_jobs=-1,\n",
    "                                   cv = cv,\n",
    "                                   verbose = 10)\n",
    "    else:\n",
    "        print(\"only xgboost or RandomForest\")\n",
    "        return None\n",
    "    grid_search.fit(X_train,y_train)\n",
    "    joblib.dump(grid_search, f\"./models/{file_name}.pkl\")\n",
    "    return grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed: 17.2min\n",
      "[Parallel(n_jobs=-1)]: Done   6 tasks      | elapsed: 17.2min\n",
      "[Parallel(n_jobs=-1)]: Done   7 tasks      | elapsed: 17.2min\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed: 17.2min\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed: 17.2min\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed: 17.2min\n",
      "[Parallel(n_jobs=-1)]: Done  11 tasks      | elapsed: 17.2min\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed: 17.2min\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/Applications/anaconda/envs/python3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    898\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 899\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    900\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/envs/python3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    516\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/envs/python3/lib/python3.6/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/envs/python3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-13006e927546>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m                        \u001b[0mtype_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xgboost\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                        \u001b[0mscoring\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"neg_mean_absolute_error\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                        file_name=\"XGB_mae_x1000_bootstrap1000_lag_1\")\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-33-0acc2efd7dda>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(ts_train_df, ts_test_df, cv, type_, scoring, file_name)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mgrid_search\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-34-36b61ac26c4c>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(X_train, y_train, type_, scoring, file_name, cv)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"only xgboost or RandomForest\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid_search\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"./models/{file_name}.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/envs/python3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/envs/python3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1189\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/envs/python3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    709\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 711\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m                 \u001b[0mall_candidate_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/envs/python3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    994\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    995\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 996\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    997\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/envs/python3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    919\u001b[0m                     \u001b[0;31m# scheduling.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m                     \u001b[0mensure_ready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_managed_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m                     \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabort_everything\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTransportableException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/envs/python3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mabort_everything\u001b[0;34m(self, ensure_ready)\u001b[0m\n\u001b[1;32m    532\u001b[0m         \"\"\"Shutdown the workers and restart a new one with the same parameters\n\u001b[1;32m    533\u001b[0m         \"\"\"\n\u001b[0;32m--> 534\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_workers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkill_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    535\u001b[0m         \u001b[0mdelete_folder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_workers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_temp_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_workers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/envs/python3/lib/python3.6/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py\u001b[0m in \u001b[0;36mshutdown\u001b[0;34m(self, wait, kill_workers)\u001b[0m\n\u001b[1;32m   1088\u001b[0m                     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1089\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1090\u001b[0;31m                 \u001b[0mqmt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1091\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m         \u001b[0mcq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_queue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/envs/python3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/envs/python3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1070\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# already determined that the C code is done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1072\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1073\u001b[0m             \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1074\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "scores = train(ts_train_df = ts_train_df,\n",
    "                       ts_test_df = ts_test_df, \n",
    "                       cv = 5,\n",
    "                       type_ = \"xgboost\",\n",
    "                       scoring = \"neg_mean_absolute_error\", \n",
    "                       file_name=\"XGB_mae_x1000_bootstrap10000_lag_1\")\n",
    "# scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
